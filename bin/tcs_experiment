import argparse
import os
from itertools import product
import numpy as np
from tc_study.experiment.downstream_task_evaluation import compute_downstream_task, \
    compute_truncated_downstream_task
from tc_study.experiment.unsupervised_evaluation import compute_truncated_unsupervised_metrics, \
    compute_normalized_unsupervised_metrics
from tc_study.experiment.unsupervised_evaluation_mp import compute_normalized_unsupervised_metrics_mp, \
    compute_truncated_unsupervised_metrics_mp
from tc_study.experiment.passive_variables import compute_passive_variable_indexes
from tc_study.experiment.synthetic_unsupervised_evaluation import all_metrics_comparison
from tc_study.experiment.passive_variables_mp import compute_passive_variable_indexes_mp


def compute_passive_variables(args):
    if args.multiprocess is not None:
        compute_passive_variable_indexes_mp(args.model_path, args.overwrite, nb_proc=args.multiprocess)
    else:
        compute_passive_variable_indexes(args.model_path, args.overwrite)


def compute_unsupervised_metrics(args):
    if args.multiprocess is not None:
        compute_unsupervised_metrics_mp(args)
    else:
        compute_unsupervised_metrics_sp(args)


def compute_unsupervised_metrics_sp(args):
    if args.truncate is True:
        compute_truncated_unsupervised_metrics(args.model_path, args.representation, overwrite=args.overwrite)
    else:
        compute_normalized_unsupervised_metrics(args.model_path, args.representation, overwrite=args.overwrite)


def compute_unsupervised_metrics_mp(args):
    if args.truncate is True:
        compute_truncated_unsupervised_metrics_mp(args.model_path, args.representation, overwrite=args.overwrite,
                                                  nb_proc=args.multiprocess)
    else:
        compute_normalized_unsupervised_metrics_mp(args.model_path, args.representation, overwrite=args.overwrite,
                                                   nb_proc=args.multiprocess)


def compute_downstream_tasks(args):
    if args.truncate is True:
        compute_truncated_downstream_task(args.model_path, args.representation, predictor=args.predictor,
                                          overwrite=args.overwrite)
    else:
        compute_downstream_task(args.model_path, args.representation, predictor=args.predictor,
                                overwrite=args.overwrite)


def compute_synthetic_eval(args):
    noises = [0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5] if args.noise is None else [args.noise]
    covs = [0.2, 0.4, 0.6, 0.8]
    covs = list(product(covs, repeat=2)) if args.cov is None else [sorted(args.cov)]
    random_state = np.random.RandomState(0)
    if noises[0] < 0 or args.size <= 0:
        raise ValueError("Size and noise must be positive")
    if not os.path.isdir(args.out_path):
        raise ValueError("out_path must be a directory")
    for cov_min, cov_max in covs:
        for noise in noises:
            for i in range(50):
                seed = random_state.randint(2 ** 32)
                all_metrics_comparison(args.size, args.out_path, seed, cov_min, cov_max, noise, args.verbose)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Reproduce truncation experiment using dislib pre-trained VAE models")
    subparsers = parser.add_subparsers()

    pv = subparsers.add_parser("passive_variables", aliases=["pv", "variables"])
    pv.add_argument("model_path", type=str, help="Path where the pre-trained models are stored")
    pv.add_argument("--overwrite", "-o", action="store_true", help="Overwrite existing results")
    pv.add_argument("--multiprocess", "-m", nargs='?', const=4, type=int, help="UNSTABLE: Performs distributed computation")
    pv.set_defaults(func=compute_passive_variables)

    mc = subparsers.add_parser("metrics_comparison", aliases=["mc"])
    mc.add_argument("size", type=int, help="Dimensionality of the latent representation")
    mc.add_argument("--out_path", "-p", type=str, default=".", help="Path used to save the results")
    mc.add_argument("--cov", "-c", type=float, nargs=2, help="Covariance range between active variables")
    mc.add_argument("--noise", "-n", type=float, help="Noise strength for active variables sampling")
    mc.add_argument("--verbose", "-v", action="store_true", help="Print the results")
    mc.set_defaults(func=compute_synthetic_eval)

    um = subparsers.add_parser("unsupervised_metrics", aliases=["um"])
    um.add_argument("model_path", type=str, help="Path where the pre-trained models are stored")
    um.add_argument("representation", type=str, choices=["mean", "sampled"],
                    help="Representation from which we need to compute unsupervised scores")
    um.add_argument("--truncate", "-t", action="store_true",
                    help="Compute truncated unsupervised metrics. Passive variables must be computed beforehand.")
    um.add_argument("--overwrite", "-o", action="store_true", help="Overwrite existing results")
    um.add_argument("--multiprocess", "-m", nargs='?', const=4, type=int, help="UNSTABLE: Performs distributed computation")
    um.set_defaults(func=compute_unsupervised_metrics)

    dt = subparsers.add_parser("downstream_tasks", aliases=["dt", "tasks"])
    dt.add_argument("model_path", type=str, help="Path where the pre-trained models are stored")
    dt.add_argument("representation", type=str, choices=["mean", "sampled"],
                    help="Representation which will be used for downstream tasks")
    dt.add_argument("predictor", type=str, choices=["logistic_regression_cv", "gradient_boosting_classifier"],
                    help="Predictor function to use")
    dt.add_argument("--truncate", "-t", action="store_true",
                    help="Compute truncated downstream tasks. Passive variables must be computed beforehand.")
    dt.add_argument("--overwrite", "-o", action="store_true", help="Overwrite existing results")
    dt.set_defaults(func=compute_downstream_tasks)

    res = parser.parse_args()
    res.func(res)
